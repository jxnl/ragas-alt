
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Simple, modular primitives for evaluating RAG systems using LLMs">
      
      
      
        <link rel="canonical" href="https://docs.ragevals.com/metrics/systematic-decomposition/">
      
      
        <link rel="prev" href="../relevance/">
      
      
        <link rel="next" href="../../usage/">
      
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.6.1, mkdocs-material-9.6.14">
    
    
      
        <title>Systematic Decomposition - RAG Evals</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.342714a4.min.css">
      
        
        <link rel="stylesheet" href="../../assets/stylesheets/palette.06af60db.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo">
  
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#systematic-decomposition-of-rag-evaluations" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="RAG Evals" class="md-header__button md-logo" aria-label="RAG Evals" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            RAG Evals
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Systematic Decomposition
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_0">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="indigo" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_0" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg>
      </label>
    
  
</form>
      
    
    
      <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script>
    
    
    
      
      
        <label class="md-header__button md-icon" for="__search">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        </label>
        <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" tabindex="0" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
      
    
    
      <div class="md-header__source">
        <a href="https://github.com/jxnl/rag-evals" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    jxnl/rag-evals
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="RAG Evals" class="md-nav__button md-logo" aria-label="RAG Evals" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54"/></svg>

    </a>
    RAG Evals
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/jxnl/rag-evals" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81"/></svg>
  </div>
  <div class="md-source__repository">
    jxnl/rag-evals
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Home
    
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
    
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested">
      
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" checked>
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    Metrics
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_2" id="__nav_2_label" tabindex="">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Metrics
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../faithfulness/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Faithfulness
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../precision/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Context Precision
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../relevance/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Answer Relevance
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  
  <span class="md-ellipsis">
    Systematic Decomposition
    
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  
  <span class="md-ellipsis">
    Systematic Decomposition
    
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#core-components" class="md-nav__link">
    <span class="md-ellipsis">
      Core Components
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#evaluation-relationships" class="md-nav__link">
    <span class="md-ellipsis">
      Evaluation Relationships
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#1-question-context-chunks-context-relevance-cq" class="md-nav__link">
    <span class="md-ellipsis">
      1. Question → Context Chunks: Context Relevance (C|Q)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2-context-chunks-answer-faithfulnessgroundedness-ac" class="md-nav__link">
    <span class="md-ellipsis">
      2. Context Chunks → Answer: Faithfulness/Groundedness (A|C)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3-question-answer-answer-relevance-aq" class="md-nav__link">
    <span class="md-ellipsis">
      3. Question → Answer: Answer Relevance (A|Q)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#4-context-chunks-answer-context-utilization" class="md-nav__link">
    <span class="md-ellipsis">
      4. Context Chunks ↔ Answer: Context Utilization
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#5-question-answer-question-answering-quality" class="md-nav__link">
    <span class="md-ellipsis">
      5. Question ↔ Answer: Question Answering Quality
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#combined-evaluation-framework" class="md-nav__link">
    <span class="md-ellipsis">
      Combined Evaluation Framework
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#implementation-example" class="md-nav__link">
    <span class="md-ellipsis">
      Implementation Example
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#relationship-to-rag-evals-implementation" class="md-nav__link">
    <span class="md-ellipsis">
      Relationship to RAG Evals Implementation
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#advantages-of-systematic-decomposition" class="md-nav__link">
    <span class="md-ellipsis">
      Advantages of Systematic Decomposition
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    
    
      
        
          
        
      
        
      
        
      
        
      
        
      
    
    
    
      
        
        
      
    
    
    <li class="md-nav__item md-nav__item--section md-nav__item--nested">
      
        
        
          
        
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type="checkbox" id="__nav_3" >
        
          
          <div class="md-nav__link md-nav__container">
            <a href="../../usage/" class="md-nav__link ">
              
  
  
  <span class="md-ellipsis">
    Usage Guide
    
  </span>
  

            </a>
            
              
              <label class="md-nav__link " for="__nav_3" id="__nav_3_label" tabindex="">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Usage Guide
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../usage/customization/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Customization
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../usage/examples/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Examples
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../usage/best_practices/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Best Practices
    
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
  
    <li class="md-nav__item">
      <a href="../../usage/troubleshooting/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    Troubleshooting
    
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
  
    <li class="md-nav__item">
      <a href="../../api/" class="md-nav__link">
        
  
  
  <span class="md-ellipsis">
    API Reference
    
  </span>
  

      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#core-components" class="md-nav__link">
    <span class="md-ellipsis">
      Core Components
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#evaluation-relationships" class="md-nav__link">
    <span class="md-ellipsis">
      Evaluation Relationships
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#1-question-context-chunks-context-relevance-cq" class="md-nav__link">
    <span class="md-ellipsis">
      1. Question → Context Chunks: Context Relevance (C|Q)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2-context-chunks-answer-faithfulnessgroundedness-ac" class="md-nav__link">
    <span class="md-ellipsis">
      2. Context Chunks → Answer: Faithfulness/Groundedness (A|C)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3-question-answer-answer-relevance-aq" class="md-nav__link">
    <span class="md-ellipsis">
      3. Question → Answer: Answer Relevance (A|Q)
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#4-context-chunks-answer-context-utilization" class="md-nav__link">
    <span class="md-ellipsis">
      4. Context Chunks ↔ Answer: Context Utilization
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#5-question-answer-question-answering-quality" class="md-nav__link">
    <span class="md-ellipsis">
      5. Question ↔ Answer: Question Answering Quality
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#combined-evaluation-framework" class="md-nav__link">
    <span class="md-ellipsis">
      Combined Evaluation Framework
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#implementation-example" class="md-nav__link">
    <span class="md-ellipsis">
      Implementation Example
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#relationship-to-rag-evals-implementation" class="md-nav__link">
    <span class="md-ellipsis">
      Relationship to RAG Evals Implementation
    </span>
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#advantages-of-systematic-decomposition" class="md-nav__link">
    <span class="md-ellipsis">
      Advantages of Systematic Decomposition
    </span>
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


  
  


<h1 id="systematic-decomposition-of-rag-evaluations">Systematic Decomposition of RAG Evaluations</h1>
<p>RAG systems involve three core components: the question, the retrieved context chunks, and the generated answer. By examining the relationships between these components, we can systematically decompose RAG evaluations into distinct metrics that assess different aspects of the system's performance.</p>
<h2 id="core-components">Core Components</h2>
<ul>
<li><strong>Question (Q)</strong>: The user's original query</li>
<li><strong>Context Chunks (C)</strong>: The pieces of information retrieved from a knowledge base</li>
<li><strong>Answer (A)</strong>: The response generated based on the question and context</li>
</ul>
<h2 id="evaluation-relationships">Evaluation Relationships</h2>
<p>We can express RAG evaluations in terms of relationships between these components. For each pair, we evaluate how well one component relates to another:</p>
<pre class="mermaid"><code>graph LR
    Q[Question] --&gt; |Relevance| C[Context Chunks]
    C --&gt; |Faithfulness| A[Answer]
    Q --&gt; |Answer Relevance| A
    C &lt;--&gt; |Context Utilization| A
    Q &lt;--&gt; |Question Answering| A</code></pre>
<p>Let's examine each of these relationships:</p>
<h2 id="1-question-context-chunks-context-relevance-cq">1. Question → Context Chunks: Context Relevance (C|Q)</h2>
<p>This evaluates how well the retrieved chunks relate to the question.</p>
<p><strong>Also known as</strong>: 
- Context Precision
- Retrieval Relevance 
- Contextual Relevancy</p>
<p><strong>Metrics in this dimension:</strong></p>
<ul>
<li><strong>Context Precision</strong>: What proportion of retrieved chunks are relevant to the question?</li>
<li><strong>Context Recall</strong>: Does the retrieved context contain all the information needed to provide a complete answer?</li>
<li><strong>Context Relevance</strong>: How relevant is each specific chunk to the question?</li>
</ul>
<p><strong>Example metric</strong>: 
- Percentage of retrieved documents relevant to the query (Myscale +4)
- In RAG Evals: <code>ChunkPrecision</code> class in <code>metrics/precision.py</code></p>
<p><strong>Example:</strong>
<div class="highlight"><pre><span></span><code>Question: &quot;What are the health benefits of meditation?&quot;
Context Chunks:
[0] &quot;Regular meditation reduces stress and anxiety.&quot;
[1] &quot;Meditation can improve focus and attention span.&quot;
[2] &quot;The history of meditation dates back to ancient civilizations.&quot;

Evaluation:
- Chunks 0 and 1: Highly relevant (directly address health benefits)
- Chunk 2: Not relevant (discusses history, not health benefits)
Context Precision Score: 2/3 = 0.67
</code></pre></div></p>
<h2 id="2-context-chunks-answer-faithfulnessgroundedness-ac">2. Context Chunks → Answer: Faithfulness/Groundedness (A|C)</h2>
<p>This evaluates how well the answer uses the provided context.</p>
<p><strong>Also known as</strong>:
- Factuality
- Correctness
- Answer Grounding</p>
<p><strong>Metrics in this dimension:</strong></p>
<ul>
<li><strong>Faithfulness/Groundedness</strong>: Does the answer only contain information supported by the context?</li>
<li><strong>Citation Accuracy</strong>: Does the answer correctly attribute information to sources?</li>
<li><strong>Hallucination Detection</strong>: Does the answer invent information not found in the context?</li>
</ul>
<p><strong>Example metric</strong>:
- Ratio of statements in the answer supported by context (Deepeval +5)
- In RAG Evals: <code>Faithfulness</code> class in <code>metrics/faithfulness.py</code></p>
<p><strong>Example:</strong>
<div class="highlight"><pre><span></span><code>Context Chunks:
[0] &quot;Regular meditation reduces stress and anxiety.&quot;
[1] &quot;Meditation can improve focus and attention span.&quot;

Answer: &quot;Meditation has several health benefits, including reduced stress and anxiety and improved focus. It also helps with depression and improves sleep quality.&quot;

Evaluation:
- &quot;Reduced stress and anxiety&quot;: Faithful (from chunk 0)
- &quot;Improved focus&quot;: Faithful (from chunk 1)
- &quot;Helps with depression&quot;: Unfaithful (not mentioned in context)
- &quot;Improves sleep quality&quot;: Unfaithful (not mentioned in context)
Faithfulness Score: 2/4 = 0.5
</code></pre></div></p>
<h2 id="3-question-answer-answer-relevance-aq">3. Question → Answer: Answer Relevance (A|Q)</h2>
<p>This evaluates how well the answer addresses the question.</p>
<p><strong>Also known as</strong>:
- Response Relevance
- Query-Response Relevance
- Answer Pertinence</p>
<p><strong>Metrics in this dimension:</strong></p>
<ul>
<li><strong>Answer Relevance</strong>: Does the answer directly address what was asked?</li>
<li><strong>Answer Completeness</strong>: Does the answer fully address all aspects of the question?</li>
<li><strong>Answer Correctness</strong>: Is the information in the answer factually accurate?</li>
<li><strong>Answer Conciseness</strong>: Is the answer appropriately detailed without unnecessary information?</li>
</ul>
<p><strong>Example metric</strong>:
- Semantic similarity between question and answer (Deepeval +10)
- In RAG Evals: <code>AnswerRelevance</code> class in <code>metrics/relevance.py</code></p>
<p><strong>Example:</strong>
<div class="highlight"><pre><span></span><code>Question: &quot;What are the health benefits of meditation?&quot;
Answer: &quot;Meditation offers numerous health benefits, including stress reduction, improved concentration, lower blood pressure, and better emotional well-being. Regular practice can help manage anxiety and depression symptoms.&quot;

Evaluation:
- Highly relevant (directly addresses health benefits)
- Complete (covers multiple aspects of health benefits)
- Concise (provides appropriate detail without meandering)
Relevance Score: 0.95
</code></pre></div></p>
<h2 id="4-context-chunks-answer-context-utilization">4. Context Chunks ↔ Answer: Context Utilization</h2>
<p>This evaluates whether the context was effectively used in generating the answer and whether the answer reflects the context.</p>
<p><strong>Also known as</strong>:
- Chunk Utility
- Context Usage
- Information Extraction</p>
<p><strong>Metrics in this dimension:</strong></p>
<ul>
<li><strong>Context Coverage</strong>: How much of the relevant context was utilized in the answer?</li>
<li><strong>Chunk Utility</strong>: Was each individual chunk utilized in the answer?</li>
</ul>
<p><strong>Example:</strong>
<div class="highlight"><pre><span></span><code>Context Chunks:
[0] &quot;Regular meditation reduces stress and anxiety.&quot;
[1] &quot;Meditation can improve focus and attention span.&quot;
[2] &quot;The history of meditation dates back to ancient civilizations.&quot;

Answer: &quot;Meditation reduces stress and improves focus.&quot;

Evaluation:
- Chunk 0: Utilized
- Chunk 1: Utilized
- Chunk 2: Not utilized
Context Utilization Score: 2/3 = 0.67
</code></pre></div></p>
<h2 id="5-question-answer-question-answering-quality">5. Question ↔ Answer: Question Answering Quality</h2>
<p>This evaluates the overall question-answering quality, regardless of the specific context used.</p>
<p><strong>Also known as</strong>:
- Answer Quality
- Response Quality
- QA Performance</p>
<p><strong>Metrics in this dimension:</strong></p>
<ul>
<li><strong>Answer Accuracy</strong>: Is the answer factually correct for the question?</li>
<li><strong>Answer Helpfulness</strong>: Does the answer provide useful information to the user?</li>
</ul>
<p><strong>Example:</strong>
<div class="highlight"><pre><span></span><code>Question: &quot;What are the health benefits of meditation?&quot;
Answer: &quot;Meditation offers numerous health benefits, including stress reduction, improved concentration, lower blood pressure, and better emotional well-being.&quot;

Evaluation:
- Accurate (provides correct health benefits)
- Helpful (gives clear, useful information)
Accuracy Score: 0.9
</code></pre></div></p>
<h2 id="combined-evaluation-framework">Combined Evaluation Framework</h2>
<p>A comprehensive RAG evaluation should assess all these relationships. This gives a complete picture of system performance:</p>
<ol>
<li><strong>Retriever Performance</strong>: Question → Context evaluation (Context Relevance)</li>
<li><strong>Generator Performance</strong>: Context → Answer evaluation (Faithfulness/Groundedness)</li>
<li><strong>End-to-End Performance</strong>: Question → Answer evaluation (Answer Relevance)</li>
</ol>
<h2 id="implementation-example">Implementation Example</h2>
<p>Here's how you might implement a comprehensive evaluation:</p>
<div class="highlight"><pre><span></span><code><span class="c1"># Conceptual example of a comprehensive evaluation</span>
<span class="k">def</span><span class="w"> </span><span class="nf">evaluate_rag_system</span><span class="p">(</span><span class="n">question</span><span class="p">,</span> <span class="n">retrieved_context</span><span class="p">,</span> <span class="n">generated_answer</span><span class="p">,</span> <span class="n">ground_truth</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="c1"># Retriever evaluation - Context Relevance (C|Q)</span>
    <span class="n">context_precision</span> <span class="o">=</span> <span class="n">evaluate_context_precision</span><span class="p">(</span><span class="n">question</span><span class="p">,</span> <span class="n">retrieved_context</span><span class="p">)</span>
    <span class="n">context_recall</span> <span class="o">=</span> <span class="n">evaluate_context_recall</span><span class="p">(</span><span class="n">retrieved_context</span><span class="p">,</span> <span class="n">ground_truth</span><span class="p">)</span> <span class="k">if</span> <span class="n">ground_truth</span> <span class="k">else</span> <span class="kc">None</span>

    <span class="c1"># Generator evaluation - Faithfulness/Groundedness (A|C)</span>
    <span class="n">faithfulness</span> <span class="o">=</span> <span class="n">evaluate_faithfulness</span><span class="p">(</span><span class="n">retrieved_context</span><span class="p">,</span> <span class="n">generated_answer</span><span class="p">)</span>

    <span class="c1"># End-to-end evaluation - Answer Relevance (A|Q)</span>
    <span class="n">answer_relevance</span> <span class="o">=</span> <span class="n">evaluate_answer_relevance</span><span class="p">(</span><span class="n">question</span><span class="p">,</span> <span class="n">generated_answer</span><span class="p">)</span>

    <span class="k">return</span> <span class="p">{</span>
        <span class="s2">&quot;retriever_performance&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;context_precision&quot;</span><span class="p">:</span> <span class="n">context_precision</span><span class="p">,</span>
            <span class="s2">&quot;context_recall&quot;</span><span class="p">:</span> <span class="n">context_recall</span>
        <span class="p">},</span>
        <span class="s2">&quot;generator_performance&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;faithfulness&quot;</span><span class="p">:</span> <span class="n">faithfulness</span>
        <span class="p">},</span>
        <span class="s2">&quot;end_to_end_performance&quot;</span><span class="p">:</span> <span class="p">{</span>
            <span class="s2">&quot;answer_relevance&quot;</span><span class="p">:</span> <span class="n">answer_relevance</span>
        <span class="p">}</span>
    <span class="p">}</span>
</code></pre></div>
<h2 id="relationship-to-rag-evals-implementation">Relationship to RAG Evals Implementation</h2>
<p>The RAG Evals library implements all three key relationships:</p>
<ol>
<li><strong>Context Relevance (C|Q)</strong>: Implemented as <code>ChunkPrecision</code> in <code>metrics/precision.py</code></li>
<li>
<p>Evaluates how well each context chunk matches the question</p>
</li>
<li>
<p><strong>Faithfulness/Groundedness (A|C)</strong>: Implemented as <code>Faithfulness</code> in <code>metrics/faithfulness.py</code></p>
</li>
<li>
<p>Evaluates how factually consistent the answer is with the provided context</p>
</li>
<li>
<p><strong>Answer Relevance (A|Q)</strong>: Implemented as <code>AnswerRelevance</code> in <code>metrics/relevance.py</code></p>
</li>
<li>Evaluates how well the answer addresses the original question</li>
</ol>
<h2 id="advantages-of-systematic-decomposition">Advantages of Systematic Decomposition</h2>
<p>Breaking down RAG evaluation into these component relationships offers several advantages:</p>
<ol>
<li><strong>Targeted Improvements</strong>: Identify which specific component needs improvement</li>
<li><strong>Comprehensive Assessment</strong>: Evaluate all aspects of the RAG pipeline</li>
<li><strong>Diagnostic Power</strong>: Pinpoint exact causes of system failures</li>
<li><strong>Component-wise Optimization</strong>: Optimize retriever and generator independently</li>
</ol>
<p>By systematically evaluating each relationship between question, context, and answer, we can build more effective and reliable RAG systems.</p>












                
              </article>
            </div>
          
          
<script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script>
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    
    
      
      <script id="__config" type="application/json">{"base": "../..", "features": ["navigation.sections", "navigation.expand", "navigation.indexes", "content.code.copy", "content.code.annotate"], "search": "../../assets/javascripts/workers/search.d50fe291.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": null}</script>
    
    
      <script src="../../assets/javascripts/bundle.13a4f30d.min.js"></script>
      
    
  </body>
</html>